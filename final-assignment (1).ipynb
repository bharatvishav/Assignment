{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  Web Scraping Assignment by Taiyo.AI","metadata":{}},{"cell_type":"markdown","source":"* NAME: Vishav Bhaat Pal \n* Coarse: Mtech in Computational and Data Science\n* College: National Institute of Technology Karnataka\n* Roll No: 222CD032","metadata":{}},{"cell_type":"markdown","source":"###  Pantaluma City","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n# Define the URL of the webpage you want to scrape\nurl = \"https://cityofpetaluma.org/planning-projects/\"\n\n# Send a GET request to the webpage\nresponse = requests.get(url)\n\n# Parse the HTML content of the webpage\nsoup = BeautifulSoup(response.content, \"html.parser\")\n\n# Find the <div> element with specific classes that contain the links\ndiv = soup.find(\"div\", class_=\"headingBox panel-widget-style panel-widget-style-for-57679-3-0-1\")\n\n# Find all <a> elements within the <div>\nlinks = div.find_all(\"a\")\n\n# Initialize an empty list to store the data\ndata_list = []\n\n\n# Iterate over the links (start from the second link)\nfor link in links[1:]:\n    # Get the URL of the webpage\n    webpage_url = link['href']\n\n    # Send a GET request to the webpage\n    webpage_response = requests.get(webpage_url)\n\n    # Parse the HTML content of the webpage\n    webpage_soup = BeautifulSoup(webpage_response.content, \"html.parser\")\n\n    # Extract data by searching for keywords\n    data = {\n        'Project Name': None,\n        'Address': None,\n        'APN': None,\n        'Applicant Name': None,\n        'Date of Decision': None,\n        'Project Description': None,\n        'Location Link': None,\n        'Posted Date': None,  # Adding Posted Date here\n        'URL': webpage_url  # Adding URL here\n    }\n\n    # Find all <strong> tags and extract the text next to them\n    for strong_tag in webpage_soup.find_all('strong'):\n        key = strong_tag.get_text(strip=True).replace(\":\", \"\")\n\n        # Extract the value considering different possible structures\n        value = \"\"\n        if strong_tag.next_sibling:\n            if isinstance(strong_tag.next_sibling, str):\n                value = strong_tag.next_sibling.strip()\n            elif strong_tag.next_sibling.name:  # If the next sibling is a tag\n                value = strong_tag.next_sibling.get_text(strip=True)\n        elif strong_tag.find_next_sibling():  # If next_sibling is not directly available\n            value = strong_tag.find_next_sibling().get_text(strip=True)\n\n        if key in data:\n            data[key] = value\n\n    # Find the anchor tag with the text \"Map It\"\n    map_link = webpage_soup.find('a', string=\"Map It\")\n\n    # Extract the href attribute if the link is found\n    location_link = map_link['href'] if map_link else None\n\n    # Add Location Link to the data dictionary\n    data['Location Link'] = location_link\n\n    # Find the <p> tag with class \"text-muted\" and extract the text\n    posted_date_tag = webpage_soup.find('p', class_='text-muted')\n    posted_date = posted_date_tag.get_text(strip=True) if posted_date_tag else None\n\n    # Add Posted Date to the data dictionary\n    data['Posted Date'] = posted_date\n\n    # Append the data to the list\n    data_list.append(data)\n\n# Create a DataFrame from the list of dictionaries\ndf = pd.DataFrame(data_list)\n\n# Reorder columns to place Location Link after Address\ndf = df[['Project Name', 'Address', 'Location Link', 'APN', 'Applicant Name', 'Date of Decision', 'Project Description', 'Posted Date', 'URL']]\n\n# Set display options to limit the width of the URL column\npd.set_option('display.max_colwidth', 100)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T15:43:04.280342Z","iopub.execute_input":"2024-05-26T15:43:04.280787Z","iopub.status.idle":"2024-05-26T15:43:13.059935Z","shell.execute_reply.started":"2024-05-26T15:43:04.280751Z","shell.execute_reply":"2024-05-26T15:43:13.058919Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Function to extract coordinates from a link\ndef extract_coordinates(link):\n    if link:\n        # Check if the link contains coordinates\n        if '@' in link:\n            # Split the link by \"@\"\n            parts = link.split(\"@\")\n            # Extract the part containing the coordinates\n            coordinates_part = parts[-1]\n            # Split the coordinates part by \",\" to separate latitude and longitude\n            coordinates = coordinates_part.split(\",\")[0:2]\n            # Join the latitude and longitude with a comma\n            return ','.join(coordinates)\n        else:\n            return None\n    else:\n        return None\n\n# Apply the function to the \"Location Link\" column\ndf['Coordinates'] = df['Location Link'].apply(extract_coordinates)\ndf.drop (['Date of Decision','Location Link'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T15:43:21.235765Z","iopub.execute_input":"2024-05-26T15:43:21.236186Z","iopub.status.idle":"2024-05-26T15:43:21.248093Z","shell.execute_reply.started":"2024-05-26T15:43:21.236138Z","shell.execute_reply":"2024-05-26T15:43:21.246762Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T15:49:50.336095Z","iopub.execute_input":"2024-05-26T15:49:50.336541Z","iopub.status.idle":"2024-05-26T15:49:50.355110Z","shell.execute_reply.started":"2024-05-26T15:49:50.336508Z","shell.execute_reply":"2024-05-26T15:49:50.353306Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                             Project Name  \\\n0                     Sepaher 4-unit Residential Building   \n1                                  MacDuff Work/Live Unit   \n2                                 The Floodway LLC Appeal   \n3                    Marin Health Petaluma – Clinical Hub   \n4  Spring Hill School Conditional Use Permit Modification   \n\n                                        Address  \\\n0                        315 Lakeville Street [   \n1                           307 Bodega Avenue [   \n2  4875 Petaluma Blvd N/4951 Stony Point Road [   \n3                     335 South McDowell Blvd [   \n4                    705 North Webster Street [   \n\n                                 APN  \\\n0                       0007-154-013   \n1                        006-301-025   \n2                        007-422-028   \n3                        007-280-046   \n4  006-371-039 and -002, 006-441-020   \n\n                                                      Applicant Name  \\\n0  Architect Nicholas Lee, on behalf of property owner Nancy Sepaher   \n1                               Brent Russell, Architect, Studio 202   \n2                                Heather Kratt (H&H Real Estate LLC)   \n3                        Patrick McGaughey, Paragon Commercial Group   \n4                          Seth Nobmann, Advanced Building Solutions   \n\n                                                                                   Project Description  \\\n0  Proposed modification of the 4-unit residential building previously approved for the vacant lot ...   \n1  The application proposes construction of a 2-story, 2,160 square foot structure to be used as on...   \n2  Heather Kratt (H&H Real Estate LLC) has filed an applicant appeal to Planning Commission of a de...   \n3  The projects propose to establish a Medical Services – Minor use within the existing 13,760 squa...   \n4  The proposed projectrequests modificationofthe existingvested Spring Hill SchoolConditional Use ...   \n\n                   Posted Date  \\\n0  Posted on December 21, 2022   \n1    Posted on January 4, 2023   \n2       Posted on May 15, 2023   \n3       Posted on May 22, 2023   \n4      Posted on July 17, 2023   \n\n                                                                                  URL  \\\n0                     https://cityofpetaluma.org/sepaher-4-unit-residential-building/   \n1                                  https://cityofpetaluma.org/macduff-work-live-unit/   \n2                                 https://cityofpetaluma.org/the-floodway-llc-appeal/   \n3                      https://cityofpetaluma.org/marin-health-petaluma-clinical-hub/   \n4  https://cityofpetaluma.org/spring-hill-school-conditional-use-permit-modification/   \n\n               Coordinates  \n0  38.2368624,-122.6353394  \n1                     None  \n2  38.2685807,-122.6733413  \n3   38.247621,-122.6248025  \n4  38.2309758,-122.6583301  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Project Name</th>\n      <th>Address</th>\n      <th>APN</th>\n      <th>Applicant Name</th>\n      <th>Project Description</th>\n      <th>Posted Date</th>\n      <th>URL</th>\n      <th>Coordinates</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sepaher 4-unit Residential Building</td>\n      <td>315 Lakeville Street [</td>\n      <td>0007-154-013</td>\n      <td>Architect Nicholas Lee, on behalf of property owner Nancy Sepaher</td>\n      <td>Proposed modification of the 4-unit residential building previously approved for the vacant lot ...</td>\n      <td>Posted on December 21, 2022</td>\n      <td>https://cityofpetaluma.org/sepaher-4-unit-residential-building/</td>\n      <td>38.2368624,-122.6353394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MacDuff Work/Live Unit</td>\n      <td>307 Bodega Avenue [</td>\n      <td>006-301-025</td>\n      <td>Brent Russell, Architect, Studio 202</td>\n      <td>The application proposes construction of a 2-story, 2,160 square foot structure to be used as on...</td>\n      <td>Posted on January 4, 2023</td>\n      <td>https://cityofpetaluma.org/macduff-work-live-unit/</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Floodway LLC Appeal</td>\n      <td>4875 Petaluma Blvd N/4951 Stony Point Road [</td>\n      <td>007-422-028</td>\n      <td>Heather Kratt (H&amp;H Real Estate LLC)</td>\n      <td>Heather Kratt (H&amp;H Real Estate LLC) has filed an applicant appeal to Planning Commission of a de...</td>\n      <td>Posted on May 15, 2023</td>\n      <td>https://cityofpetaluma.org/the-floodway-llc-appeal/</td>\n      <td>38.2685807,-122.6733413</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Marin Health Petaluma – Clinical Hub</td>\n      <td>335 South McDowell Blvd [</td>\n      <td>007-280-046</td>\n      <td>Patrick McGaughey, Paragon Commercial Group</td>\n      <td>The projects propose to establish a Medical Services – Minor use within the existing 13,760 squa...</td>\n      <td>Posted on May 22, 2023</td>\n      <td>https://cityofpetaluma.org/marin-health-petaluma-clinical-hub/</td>\n      <td>38.247621,-122.6248025</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Spring Hill School Conditional Use Permit Modification</td>\n      <td>705 North Webster Street [</td>\n      <td>006-371-039 and -002, 006-441-020</td>\n      <td>Seth Nobmann, Advanced Building Solutions</td>\n      <td>The proposed projectrequests modificationofthe existingvested Spring Hill SchoolConditional Use ...</td>\n      <td>Posted on July 17, 2023</td>\n      <td>https://cityofpetaluma.org/spring-hill-school-conditional-use-permit-modification/</td>\n      <td>38.2309758,-122.6583301</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Rohnert Park City","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\n\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win 64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'\n}\n\nurl = 'https://www.rpcity.org/city_hall/departments/development_services/engineering/projects_in_progress'\n\n# Get the webpage content\nresponse = requests.get(url, headers=headers)\nwebpage = response.text\n\n# Create BeautifulSoup object\nsoup = BeautifulSoup(webpage, 'lxml')\n\n# Extract Title\nall_h3_tags = soup.find_all('h3')\ntitles = [tag.text.strip() for tag in all_h3_tags[2:]]\n\n# Extract Description\ndescription_tags = soup.find_all('div', class_='accordion-content')\ndescriptions = [tag.get_text(strip=True) for tag in description_tags]\n\n# Extract Location\nlocation_strong_tags = soup.find_all('strong', string=re.compile(r'Location:', re.IGNORECASE))\nlocations = []\nfor strong_tag in location_strong_tags:\n    next_sibling = strong_tag.next_sibling\n    while next_sibling and (next_sibling.name == 'strong' or next_sibling.strip() == '&nbsp;' or not next_sibling.strip()):\n        next_sibling = next_sibling.next_sibling\n    if next_sibling:\n        locations.append(next_sibling.strip())\n\n# Extract Summary\nsummary_strong_tags = soup.find_all('strong', string=re.compile(r'Summary:', re.IGNORECASE))\nsummaries = []\nfor strong_tag in summary_strong_tags:\n    next_sibling = strong_tag.next_sibling\n    while next_sibling and (next_sibling.name == 'strong' or next_sibling.strip() == '&nbsp;' or not next_sibling.strip()):\n        next_sibling = next_sibling.next_sibling\n    if next_sibling:\n        summaries.append(next_sibling.strip())\n\n# Extract Project Status\nproject_status_strong_tags = soup.find_all('strong', string=re.compile(r'PROJECT STATUS', re.IGNORECASE))\nproject_statuses = []\nfor strong_tag in project_status_strong_tags:\n    next_sibling = strong_tag.next_sibling\n    while next_sibling and (next_sibling.name == 'strong' or next_sibling.strip() == '&nbsp;' or not next_sibling.strip()):\n        next_sibling = next_sibling.next_sibling\n    if next_sibling:\n        if next_sibling.name == 'br':\n            next_sibling = next_sibling.next_sibling\n        if next_sibling and next_sibling.strip():\n            project_status_text = next_sibling.strip()\n            project_statuses.append(project_status_text)\n        else:\n            next_sibling = next_sibling.next_sibling\n            while next_sibling and not next_sibling.strip():\n                next_sibling = next_sibling.next_sibling\n            if next_sibling and next_sibling.strip():\n                project_status_text = next_sibling.strip()\n                project_statuses.append(project_status_text)\n\n# Ensure all lists have the same length\nmin_length = min(len(titles), len(descriptions), len(locations), len(summaries), len(project_statuses))\ntitles = titles[:min_length]\ndescriptions = descriptions[:min_length]\nlocations = locations[:min_length]\nsummaries = summaries[:min_length]\nproject_statuses = project_statuses[:min_length]\n\n# Create DataFrame\ndf = pd.DataFrame({\n    'Title': titles,\n    'Description': descriptions,\n    'Location': locations,\n    'Summary': summaries,\n    'Project_Status': project_statuses\n})","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:36:08.674504Z","iopub.execute_input":"2024-05-26T16:36:08.675657Z","iopub.status.idle":"2024-05-26T16:36:10.789443Z","shell.execute_reply.started":"2024-05-26T16:36:08.675620Z","shell.execute_reply":"2024-05-26T16:36:10.788280Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:36:26.177420Z","iopub.execute_input":"2024-05-26T16:36:26.177816Z","iopub.status.idle":"2024-05-26T16:36:26.190664Z","shell.execute_reply.started":"2024-05-26T16:36:26.177776Z","shell.execute_reply":"2024-05-26T16:36:26.189447Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                               Title  \\\n0  Various Streets Preventative Maintenance, Proj...   \n1  Highway 101 Bike and Pedestrian Crossing Feasi...   \n2  State Farm Drive Rehabilitation, Project No. 2...   \n3  2019 Pavement Maintenance Project, Project No....   \n4  Roundabout - Southwest Blvd/Commerce Blvd, Pro...   \n\n                                         Description  \\\n0  Project also known as L-Section Rehabilitation...   \n1  Project funded by Measure M.Location:The feasi...   \n2  Project funded by Measure M and SB-1.Location:...   \n3  Project also known as J & G Section Pavement R...   \n4  Project funded by Public Facilities, Fees, the...   \n\n                                            Location  \\\n0                         L-Section in Rohnert Park.   \n1  The feasibility study will study existing and ...   \n2  State Farm Drive from Rohnert Park Expressway ...   \n3                                     J & G Sections   \n4  Intersection of Southwest Boulevard and Commer...   \n\n                                             Summary  \\\n0  The work is described generally as asphalt con...   \n1  The US 101 freeway is a major barrier to east-...   \n2  The work is described generally as Alternate A...   \n3  The work is described generally as asphalt con...   \n4  This work is to address roadway safety by repl...   \n\n                                      Project_Status  \n0                                      : Spring 2021  \n1  : Feasibility study still in preliminary data ...  \n2                               : Under construction  \n3                    : Complete as of April 3, 2020.  \n4                                 Construction phase  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Description</th>\n      <th>Location</th>\n      <th>Summary</th>\n      <th>Project_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Various Streets Preventative Maintenance, Proj...</td>\n      <td>Project also known as L-Section Rehabilitation...</td>\n      <td>L-Section in Rohnert Park.</td>\n      <td>The work is described generally as asphalt con...</td>\n      <td>: Spring 2021</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Highway 101 Bike and Pedestrian Crossing Feasi...</td>\n      <td>Project funded by Measure M.Location:The feasi...</td>\n      <td>The feasibility study will study existing and ...</td>\n      <td>The US 101 freeway is a major barrier to east-...</td>\n      <td>: Feasibility study still in preliminary data ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>State Farm Drive Rehabilitation, Project No. 2...</td>\n      <td>Project funded by Measure M and SB-1.Location:...</td>\n      <td>State Farm Drive from Rohnert Park Expressway ...</td>\n      <td>The work is described generally as Alternate A...</td>\n      <td>: Under construction</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019 Pavement Maintenance Project, Project No....</td>\n      <td>Project also known as J &amp; G Section Pavement R...</td>\n      <td>J &amp; G Sections</td>\n      <td>The work is described generally as asphalt con...</td>\n      <td>: Complete as of April 3, 2020.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Roundabout - Southwest Blvd/Commerce Blvd, Pro...</td>\n      <td>Project funded by Public Facilities, Fees, the...</td>\n      <td>Intersection of Southwest Boulevard and Commer...</td>\n      <td>This work is to address roadway safety by repl...</td>\n      <td>Construction phase</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Santa Maria City","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n# Define headers\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'\n}\n\n# Make a request to the URL with defined headers\nresponse = requests.get('https://www.santamariagroup.com/projects', headers=headers)\n\n# Extract text from the response\nwebpage = response.text\n\n# Parse the webpage with BeautifulSoup\nsoup = BeautifulSoup(webpage, 'html.parser')\n\n# Initialize lists to store data\ntitles = []\ndescriptions = []\nlocations = []\nstatuses = []\nclients = []\nroles = []\n\n# Extract titles from <h3> tags\nfor h3 in soup.find_all('h3'):\n    titles.append(h3.text.strip())\n\n# Find all <p> tags\nparagraphs = soup.find_all('p')\n\n# Initialize variables to store temporary values\ndescription = location = status = client = role = None\n\n# Iterate through each <p> tag\nfor p in paragraphs:\n    # Extract text content of the <p> tag and strip whitespace\n    text = p.text.strip()\n    \n    # Check if the text starts with \"Location:\", \"Status:\", \"Client:\", or \"SMG Role:\"\n    if text.startswith(\"Location:\"):\n        # If so, update the corresponding variable\n        location = text.split(\": \")[1]\n    elif text.startswith(\"Status:\"):\n        status = text.split(\": \")[1]\n    elif text.startswith(\"Client:\"):\n        client = text.split(\": \")[1]\n    elif text.startswith(\"SMG Role:\"):\n        role = text.split(\": \")[1]\n    else:\n        # If none of the above conditions are met, assume it's a description\n        if description:\n            # If description already exists, append it to the list along with other details\n            descriptions.append(description)\n            locations.append(location)\n            statuses.append(status)\n            clients.append(client)\n            roles.append(role)\n        # Update description variable with current text\n        description = text\n\n# Append the last description to the list\ndescriptions.append(description)\n\n# Ensure all lists have the same length\nmax_length = max(len(titles), len(descriptions), len(locations), len(statuses), len(clients), len(roles))\ntitles += [''] * (max_length - len(titles))\ndescriptions += [''] * (max_length - len(descriptions))\nlocations += [''] * (max_length - len(locations))\nstatuses += [''] * (max_length - len(statuses))\nclients += [''] * (max_length - len(clients))\nroles += [''] * (max_length - len(roles))\n\n# Create a DataFrame\ndf = pd.DataFrame({\n    \"Title\": titles,\n    \"Description\": descriptions,\n    \"Location\": locations,\n    \"Status\": statuses,\n    \"Client\": clients,\n    \"SMG Role\": roles\n})\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:40:29.143852Z","iopub.execute_input":"2024-05-26T16:40:29.144267Z","iopub.status.idle":"2024-05-26T16:40:29.391151Z","shell.execute_reply.started":"2024-05-26T16:40:29.144225Z","shell.execute_reply":"2024-05-26T16:40:29.390165Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:40:39.042305Z","iopub.execute_input":"2024-05-26T16:40:39.042710Z","iopub.status.idle":"2024-05-26T16:40:39.056467Z","shell.execute_reply.started":"2024-05-26T16:40:39.042680Z","shell.execute_reply":"2024-05-26T16:40:39.055360Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                 Title  \\\n0                   All Nations Church   \n1                  Alta Public Schools   \n2                  Columbia Apartments   \n3                 Doheny Eye Institute   \n4  Emerson College - West Coast Campus   \n\n                                         Description  \\\n0  Conditional Use And Land Use Variance For A 25...   \n1  Services:  SMG Expedited The Process Of Going ...   \n2                     127 Units Preservation Project   \n3  Variance To Receive A Parking Reduction For Th...   \n4  Development Of West Coast Campus On Sunset Bou...   \n\n                                            Location  \\\n0                                Tujunga, California   \n1                                Tujunga, California   \n2  Scattered Sites Located In Council Districts 1...   \n3                            Los Angeles, California   \n4                               Hollywood California   \n\n                                              Status  \\\n0  2014 Approved Condition Compliance And Approve...   \n1                                          Completed   \n2   Financing Received 4% Tax Credits And Bonds 2012   \n3                Approved And Completed January 2013   \n4                       Building Completed July 2013   \n\n                                Client  \\\n0                   All Nations Church   \n1                  Alta Public Schools   \n2  Intercontinental Affordable Housing   \n3                 Doheny Eye Institute   \n4                      Emerson College   \n\n                                            SMG Role  \n0  Land Use Consultant And Owner’s Representative...  \n1  Successfully Expedited The Process Of Aiding A...  \n2  Represented Client On 4% Financing And TEFRA A...  \n3  Lead Lobbyist And Land Use Consultant For The ...  \n4  Representation Of Client With The City Of LA F...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Description</th>\n      <th>Location</th>\n      <th>Status</th>\n      <th>Client</th>\n      <th>SMG Role</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>All Nations Church</td>\n      <td>Conditional Use And Land Use Variance For A 25...</td>\n      <td>Tujunga, California</td>\n      <td>2014 Approved Condition Compliance And Approve...</td>\n      <td>All Nations Church</td>\n      <td>Land Use Consultant And Owner’s Representative...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alta Public Schools</td>\n      <td>Services:  SMG Expedited The Process Of Going ...</td>\n      <td>Tujunga, California</td>\n      <td>Completed</td>\n      <td>Alta Public Schools</td>\n      <td>Successfully Expedited The Process Of Aiding A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Columbia Apartments</td>\n      <td>127 Units Preservation Project</td>\n      <td>Scattered Sites Located In Council Districts 1...</td>\n      <td>Financing Received 4% Tax Credits And Bonds 2012</td>\n      <td>Intercontinental Affordable Housing</td>\n      <td>Represented Client On 4% Financing And TEFRA A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Doheny Eye Institute</td>\n      <td>Variance To Receive A Parking Reduction For Th...</td>\n      <td>Los Angeles, California</td>\n      <td>Approved And Completed January 2013</td>\n      <td>Doheny Eye Institute</td>\n      <td>Lead Lobbyist And Land Use Consultant For The ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Emerson College - West Coast Campus</td>\n      <td>Development Of West Coast Campus On Sunset Bou...</td>\n      <td>Hollywood California</td>\n      <td>Building Completed July 2013</td>\n      <td>Emerson College</td>\n      <td>Representation Of Client With The City Of LA F...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Fontana City","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n# Define the headers for the HTTP request\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n\n# List of URLs to scrape\nurls = [\n    'https://www.fontanaca.gov/3417/Commercial-Use-Development-Projects',\n    'https://www.fontanaca.gov/3416/Civic-Use-Development-Projects',\n    'https://www.fontanaca.gov/3418/Residential-Developments'\n]\n\n# Create lists to hold the scraped data\ndata = []\n\n# Function to scrape a single URL\ndef scrape_url(url):\n    webpage = requests.get(url, headers=headers).text\n    soup = BeautifulSoup(webpage, 'lxml')\n    \n    for project in soup.find_all('h3', class_=\"subhead2\"):\n        title = project.text.strip()\n        ul = project.find_next_sibling('ul')\n        \n        if ul:\n            li_elements = ul.find_all('li')\n            \n            # Extract location\n            if len(li_elements) > 0:\n                location_element = li_elements[0]\n                if location_element.find('span'):\n                    location = location_element.find('span').text.strip()\n                else:\n                    location = location_element.text.split(\":\")[1].strip() if \":\" in location_element.text else \"N/A\"\n            else:\n                location = \"N/A\"\n            \n            # Extract expected timeline\n            if len(li_elements) > 1:\n                timeline_element = li_elements[1]\n                timeline = timeline_element.text.split(\":\")[1].strip() if \":\" in timeline_element.text else \"N/A\"\n            else:\n                timeline = \"N/A\"\n            \n            # Extract description\n            if len(li_elements) > 2:\n                description_element = li_elements[2]\n                description = description_element.text.split(\":\")[1].strip() if \":\" in description_element.text else \"N/A\"\n            else:\n                description = \"N/A\"\n            \n            # Append the data to the list with the URL\n            data.append({\n                'Title': title,\n                'URL': url,\n                'Location': location,\n                'Expected Timeline': timeline,\n                'Description': description\n            })\n\n# Loop through the URLs and scrape each one\nfor url in urls:\n    scrape_url(url)\n\n# Create a DataFrame from the list of data with the specified column order\ndf = pd.DataFrame(data, columns=['Title', 'URL', 'Location', 'Expected Timeline', 'Description'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:49:51.907588Z","iopub.execute_input":"2024-05-26T16:49:51.908030Z","iopub.status.idle":"2024-05-26T16:49:54.891440Z","shell.execute_reply.started":"2024-05-26T16:49:51.907996Z","shell.execute_reply":"2024-05-26T16:49:54.890290Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:50:21.991906Z","iopub.execute_input":"2024-05-26T16:50:21.992522Z","iopub.status.idle":"2024-05-26T16:50:22.004444Z","shell.execute_reply.started":"2024-05-26T16:50:21.992490Z","shell.execute_reply":"2024-05-26T16:50:22.003308Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                              Title  \\\n0    Chrysler, Dodge, Ram, and Jeep   \n1                   Fontana Hyundai   \n2  Northgate Market Shopping Center   \n3                   La Quinta Hotel   \n4       Marriott Towne Place Suites   \n\n                                                 URL  \\\n0  https://www.fontanaca.gov/3417/Commercial-Use-...   \n1  https://www.fontanaca.gov/3417/Commercial-Use-...   \n2  https://www.fontanaca.gov/3417/Commercial-Use-...   \n3  https://www.fontanaca.gov/3417/Commercial-Use-...   \n4  https://www.fontanaca.gov/3417/Commercial-Use-...   \n\n                                            Location  \\\n0  South Highland Ave. and Oleander Ave. in the S...   \n1            16850 S Highland Ave, Fontana, CA 92336   \n2  Sierra Ave and San Bernardino Ave. in the Nort...   \n3  Juniper Ave. and Slover Ave. in the Southeast ...   \n4                                  10530 Sierra Ave.   \n\n                 Expected Timeline  \\\n0           Winter 2022 Completion   \n1                      Summer 2021   \n2  Construction Starts Winter 2022   \n3     Currently Under Construction   \n4  Construction Starts Winter 2022   \n\n                                         Description  \n0  The new Chrysler, Dodge, and Jeep dealership w...  \n1                                                N/A  \n2  A new shopping center has been approved for Ce...  \n3  The new hotel will consist of four stories and...  \n4  Fontana will soon be home to Marriott Towne Pl...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>URL</th>\n      <th>Location</th>\n      <th>Expected Timeline</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chrysler, Dodge, Ram, and Jeep</td>\n      <td>https://www.fontanaca.gov/3417/Commercial-Use-...</td>\n      <td>South Highland Ave. and Oleander Ave. in the S...</td>\n      <td>Winter 2022 Completion</td>\n      <td>The new Chrysler, Dodge, and Jeep dealership w...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fontana Hyundai</td>\n      <td>https://www.fontanaca.gov/3417/Commercial-Use-...</td>\n      <td>16850 S Highland Ave, Fontana, CA 92336</td>\n      <td>Summer 2021</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Northgate Market Shopping Center</td>\n      <td>https://www.fontanaca.gov/3417/Commercial-Use-...</td>\n      <td>Sierra Ave and San Bernardino Ave. in the Nort...</td>\n      <td>Construction Starts Winter 2022</td>\n      <td>A new shopping center has been approved for Ce...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>La Quinta Hotel</td>\n      <td>https://www.fontanaca.gov/3417/Commercial-Use-...</td>\n      <td>Juniper Ave. and Slover Ave. in the Southeast ...</td>\n      <td>Currently Under Construction</td>\n      <td>The new hotel will consist of four stories and...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Marriott Towne Place Suites</td>\n      <td>https://www.fontanaca.gov/3417/Commercial-Use-...</td>\n      <td>10530 Sierra Ave.</td>\n      <td>Construction Starts Winter 2022</td>\n      <td>Fontana will soon be home to Marriott Towne Pl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Thousand Oaks City","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef scrape_project_details(url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win 64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'\n    }\n    response = requests.get(url, headers=headers)\n    soup = BeautifulSoup(response.text, 'lxml')\n    \n    data = {}\n\n    # Scrape the h1 tag with the specified class for the title\n    title_tag = soup.find('h1', class_='titlewidget-title')\n    if title_tag:\n        data['Title'] = title_tag.text.strip()\n\n    # List of relevant sections to include\n    include_sections = {\n        \"Project Description\": [\"h3\", \"strong\"],\n        \"Project Timeline\": [\"h3\", \"strong\"],\n        \"Project Timeframe\": [\"h3\", \"strong\"],  # Adding Project Timeframe\n        \"Budget/Funding\": [\"h3\", \"strong\"],\n        \"Budget\": [\"h3\", \"strong\"],  # Adding Budget\n        \"Project Manager Contact Information:\": [\"h3\", \"strong\"],\n        \"Project Contacts:\": [\"h3\", \"strong\"]  # Adding Project Contacts\n    }\n\n    # Function to extract text from tags\n    def extract_text(tag):\n        if tag.name == 'ul':\n            return ' '.join(li.text.strip() for li in tag.find_all('li'))\n        return tag.text.strip()\n\n    # Extract sections\n    for section, tags in include_sections.items():\n        for tag in tags:\n            # Search for tags that contain the section text\n            section_tag = soup.find(tag, string=lambda text: text and section.lower() in text.lower())\n            if section_tag:\n                next_tag = section_tag.find_next_sibling()\n                content = []\n                while next_tag and next_tag.name not in ['h3', 'strong']:\n                    content.append(extract_text(next_tag))\n                    next_tag = next_tag.find_next_sibling()\n                if content:\n                    # Use the common key \"Project Timeline\" for both \"Project Timeline\" and \"Project Timeframe\"\n                    if section in [\"Project Timeline\", \"Project Timeframe\"]:\n                        data[\"Project Timeline\"] = ' '.join(content).strip()\n                    # Use the common key \"Budget/Funding\" for both \"Budget\" and \"Budget/Funding\"\n                    elif section in [\"Budget\", \"Budget/Funding\"]:\n                        data[\"Budget/Funding\"] = ' '.join(content).strip()\n                    # Use the common key \"Project Manager Contact Information:\" for both variations\n                    elif section in [\"Project Manager Contact Information:\", \"Project Contacts:\"]:\n                        data[\"Project Manager Contact Information:\"] = ' '.join(content).strip()\n                    else:\n                        data[section] = ' '.join(content).strip()\n                break\n\n    # Handle case where content is in <ul> and <li> tags under a <p><strong>...</strong></p>\n    for section, tags in include_sections.items():\n        for tag in tags:\n            section_tag = soup.find(tag, string=lambda text: text and section.lower() in text.lower())\n            if section_tag:\n                # Check if next sibling is <ul>\n                next_tag = section_tag.find_parent().find_next_sibling()\n                content = []\n                while next_tag and next_tag.name not in ['h3', 'strong', 'p']:\n                    if next_tag.name == 'ul':\n                        content.append(extract_text(next_tag))\n                    next_tag = next_tag.find_next_sibling()\n                if content:\n                    # Use the common key \"Project Timeline\" for both \"Project Timeline\" and \"Project Timeframe\"\n                    if section in [\"Project Timeline\", \"Project Timeframe\"]:\n                        data[\"Project Timeline\"] = ' '.join(content).strip()\n                    # Use the common key \"Budget/Funding\" for both \"Budget\" and \"Budget/Funding\"\n                    elif section in [\"Budget\", \"Budget/Funding\"]:\n                        data[\"Budget/Funding\"] = ' '.join(content).strip()\n                    # Use the common key \"Project Manager Contact Information:\" for both variations\n                    elif section in [\"Project Manager Contact Information:\", \"Project Contacts:\"]:\n                        data[\"Project Manager Contact Information:\"] = ' '.join(content).strip()\n                    else:\n                        data[section] = ' '.join(content).strip()\n                break\n\n    return data\n\n# Correct URL should be specified here\nbase_url = 'https://www.toaks.org/departments/public-works/construction'  \n\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win 64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'\n}\n# Get the initial page to extract project URLs\nresponse = requests.get(base_url, headers=headers)\nsoup = BeautifulSoup(response.text, 'lxml')\n\n# Extract project URLs\nproject_urls = []\nfor h3 in soup.find_all('h3'):\n    a_tag = h3.find('a')\n    if a_tag:\n        project_urls.append(a_tag['href'])\n\n# Initialize an empty list to store data\ndata_list = []\n\n# Iterate over project URLs to scrape project information\nfor url in project_urls:\n    project_data = scrape_project_details(url)\n    if project_data:\n        data_list.append(project_data)\n\n# Convert the data list to a pandas DataFrame\ndf = pd.DataFrame(data_list)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:43:57.476706Z","iopub.execute_input":"2024-05-26T16:43:57.477171Z","iopub.status.idle":"2024-05-26T16:45:18.952712Z","shell.execute_reply.started":"2024-05-26T16:43:57.477138Z","shell.execute_reply":"2024-05-26T16:45:18.951530Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:45:42.506372Z","iopub.execute_input":"2024-05-26T16:45:42.506856Z","iopub.status.idle":"2024-05-26T16:45:42.521513Z","shell.execute_reply.started":"2024-05-26T16:45:42.506821Z","shell.execute_reply":"2024-05-26T16:45:42.519731Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                               Title  \\\n0                              Conejo Canyons Bridge   \n1          Electric Vehicle Charging Station Project   \n2      CI 5435- Erbes Road Fence Replacement Project   \n3                 MI 2574 Guard Rail Repairs Project   \n4  Hillcrest Drive Bike Lane and Pedestrian Impro...   \n\n                                 Project Description  \\\n0  The project includes construction of a steel b...   \n1  The work includes site preparation, electrical...   \n2  The project includes replacement of 3,500 ft e...   \n3                                                NaN   \n4                                                NaN   \n\n                                    Project Timeline  \\\n0  The project construction started in September ...   \n1                                                NaN   \n2  The project is currently in the final design p...   \n3                                                NaN   \n4  The project is currently in the preliminary de...   \n\n                                      Budget/Funding  \\\n0  The total estimated project cost is $3,200,000...   \n1  Construction contract has been awarded to Pref...   \n2  The total estimated project cost is $330,000 a...   \n3                                                NaN   \n4  The total project budget is $2,890,000. The cu...   \n\n                Project Manager Contact Information:  \n0  Saeed Zolfaghari, PE Associate Engineer szolfa...  \n1                                                NaN  \n2                                                NaN  \n3                                                NaN  \n4                                                NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Project Description</th>\n      <th>Project Timeline</th>\n      <th>Budget/Funding</th>\n      <th>Project Manager Contact Information:</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Conejo Canyons Bridge</td>\n      <td>The project includes construction of a steel b...</td>\n      <td>The project construction started in September ...</td>\n      <td>The total estimated project cost is $3,200,000...</td>\n      <td>Saeed Zolfaghari, PE Associate Engineer szolfa...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Electric Vehicle Charging Station Project</td>\n      <td>The work includes site preparation, electrical...</td>\n      <td>NaN</td>\n      <td>Construction contract has been awarded to Pref...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CI 5435- Erbes Road Fence Replacement Project</td>\n      <td>The project includes replacement of 3,500 ft e...</td>\n      <td>The project is currently in the final design p...</td>\n      <td>The total estimated project cost is $330,000 a...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MI 2574 Guard Rail Repairs Project</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hillcrest Drive Bike Lane and Pedestrian Impro...</td>\n      <td>NaN</td>\n      <td>The project is currently in the preliminary de...</td>\n      <td>The total project budget is $2,890,000. The cu...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Arceta City","metadata":{}},{"cell_type":"code","source":"pip install requests # For Arceta\n!pip install selenium\npip install tabulate\npip install beautifulsoup4","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:55:41.726473Z","iopub.execute_input":"2024-05-26T16:55:41.726907Z","iopub.status.idle":"2024-05-26T16:55:57.031062Z","shell.execute_reply.started":"2024-05-26T16:55:41.726874Z","shell.execute_reply":"2024-05-26T16:55:57.029672Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom IPython.display import display, HTML","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:58:34.606581Z","iopub.execute_input":"2024-05-26T16:58:34.606994Z","iopub.status.idle":"2024-05-26T16:58:34.613541Z","shell.execute_reply.started":"2024-05-26T16:58:34.606962Z","shell.execute_reply":"2024-05-26T16:58:34.612215Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nurl = \"https://www.cityofarcata.org/421/Completed-Projects\"\npage = requests.get(url)\nsoup = BeautifulSoup(page.content, \"html.parser\")\n\ndata = []\ntable = soup.find(\"table\")\nrows = table.find_all(\"tr\")\n\nfor row in rows:\n    cols = row.find_all(\"td\")\n    cols = [ele.text.strip() for ele in cols]\n    data.append([ele for ele in cols if ele])\n\ndf = pd.DataFrame(data, columns=[\"City Project Title\", \"Project Description\", \"Project Status\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T16:59:13.561540Z","iopub.execute_input":"2024-05-26T16:59:13.561930Z","iopub.status.idle":"2024-05-26T16:59:14.537846Z","shell.execute_reply.started":"2024-05-26T16:59:13.561901Z","shell.execute_reply":"2024-05-26T16:59:14.536952Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"html = df.head().to_html(index=False)\ndisplay(HTML(html))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:01:16.821875Z","iopub.execute_input":"2024-05-26T17:01:16.822306Z","iopub.status.idle":"2024-05-26T17:01:16.832678Z","shell.execute_reply.started":"2024-05-26T17:01:16.822273Z","shell.execute_reply":"2024-05-26T17:01:16.831125Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>City Project Title</th>\n      <th>Project Description</th>\n      <th>Project Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <td>8th &amp; 9th Streets Improvement Project</td>\n      <td>The City of Arcata contracted with RAO Construction for the 8th &amp; 9th Streets Improvement Project. Work on 8th &amp; 9th Streets took place between I Street &amp; K Street and involved: (1) removing and installing new ADA compliant sidewalks and (2) street improvements, which included crosswalks, intersections, parking, bike lanes, and drainage. Additionally, to further remind, street improvements included updates on paths of travel. 9th street became a one-way vehicle travel to K Street and 8th Street became a one-way vehicle travel from K Street to F Street.</td>\n      <td>Complete</td>\n    </tr>\n    <tr>\n      <td>Arcata South I Street Boat Launch Facility Improvement Project</td>\n      <td>This project involved the installation of a boat launch, concrete abutment, minor concrete work, pavement, drainage, and accessibility improvements.The project took place at the end of South I Street in the Arcata Marsh Wildlife Sanctuary, at the edge of Humboldt Bay.Project Plans can be found here.</td>\n      <td>CompleteIf there are any issues or deficiencies observed by the public, please contact Jak Kirchubel, Engineering Technician I; Office: (707)-825-2174 or via email: jkirchubel@cityofarcata.org</td>\n    </tr>\n    <tr>\n      <td>2023 Arcata Annual Paving Project</td>\n      <td>This project involved grinding and replacing existing asphalt; sidewalk infill and replacement; accessible ramp construction; AC curb construction; drainage improvements; curb and gutter construction; wedge and roadway conform grinding; asphalt concrete overlay; raise manhole, valve, cleanout and monument covers to grade; installation of truncated domes; and roadway striping and legends. The project included grinding asphalt, paving, curbs, sidewalk, compaction, pavement markings/stripings and signage.This project occurred along H Street between Sunset Avenue and 11th Street, G Street between 5th and 7th Street, and West End Road between Giuntoli Lane and the City Limits.Project Plans can be found here.</td>\n      <td>CompleteIf there are any issues or deficiencies that are observed by the public, please contact Jak Kirchubel, Engineering Technician I; Office: (707)-825-2174 or via email: jkirchubel@cityofarcata.org</td>\n    </tr>\n    <tr>\n      <td>Fiber Installation Project</td>\n      <td>Lightwave Construction is working in portions of Arcata to construct new conduit and fiber infrastructure for Vero Networks. This system will enable broadband connectivity to high-bandwidth customers in the Arcata/Eureka area such as large enterprise, education, government &amp; carrier/last mile providers.As a state-recognized public utility, Vero Networks will be performing work in the City right-of-way under a permit issued by the City of Arcata. The City has imposed certain requirements to lessen the impact of this work in Arcata’s neighborhoods, which can be found in more detail here.Project plans can be viewed for Phase I &amp; Phase II of the project.</td>\n      <td>Complete</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Daily City","metadata":{}},{"cell_type":"code","source":"pip install tabula-py # Daily City","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:03:08.631783Z","iopub.execute_input":"2024-05-26T17:03:08.632460Z","iopub.status.idle":"2024-05-26T17:03:23.717792Z","shell.execute_reply.started":"2024-05-26T17:03:08.632430Z","shell.execute_reply":"2024-05-26T17:03:23.716599Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Collecting tabula-py\n  Downloading tabula_py-2.9.3-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: pandas>=0.25.3 in /opt/conda/lib/python3.10/site-packages (from tabula-py) (2.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tabula-py) (1.26.4)\nRequirement already satisfied: distro in /opt/conda/lib/python3.10/site-packages (from tabula-py) (1.9.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25.3->tabula-py) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25.3->tabula-py) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25.3->tabula-py) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\nDownloading tabula_py-2.9.3-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tabula-py\nSuccessfully installed tabula-py-2.9.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tabula\n\n# PDF link\npdf_url = \"https://www.dalycity.org/DocumentCenter/View/7309/Current-Projects-List---Updated-January-1-2023-PDF?bidId=\"\n\n# Read PDF and extract tables\ntables = tabula.read_pdf(pdf_url, pages='all', multiple_tables=True)\n\n# Combine tables into a single DataFrame\ndf = pd.concat(tables)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:04:05.437364Z","iopub.execute_input":"2024-05-26T17:04:05.438326Z","iopub.status.idle":"2024-05-26T17:04:10.198468Z","shell.execute_reply.started":"2024-05-26T17:04:05.438282Z","shell.execute_reply":"2024-05-26T17:04:10.197258Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T17:04:22.466805Z","iopub.execute_input":"2024-05-26T17:04:22.467529Z","iopub.status.idle":"2024-05-26T17:04:22.502585Z","shell.execute_reply.started":"2024-05-26T17:04:22.467495Z","shell.execute_reply":"2024-05-26T17:04:22.501433Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                        Project Name  \\\n0                          Point Martin\\r- Phase One   \n1                          Point Martin\\r- Phase Two   \n2                   Pacific Place Retail\\rConversion   \n3  Mission Street/\\rGoethe Street\\rMixed-Use Buil...   \n4                        Eastmoor\\rMixed-Use\\r(CORE)   \n\n                                    Application Type  \\\n0                                  Major subdivision   \n1        General Plan\\rAmendment and\\rPD Zone Change   \n2  Zone Change\\rMajor Subdivision\\rDesign Review\\...   \n3                      Use Permit and\\rDesign Review   \n4                      Use Permit and\\rDesign Review   \n\n                                       Plan Case No.  \\\n0                                     SUB-6-15-11016   \n1  GPA-01-16-011884\\rPD-10-15-11781\\rCEQA-10-15-1...   \n2  ZC-4-16-12036\\rSUB-4-16-12037\\rUP-4-16-12038\\r...   \n3    SUB-12-20-14799\\rUPR-9-16-12301\\rDR-9-16-012302   \n4                  UPR-6-19-14076 and\\rDR-6-19-14077   \n\n                                        Location/APN  \\\n0  Steve Courter Way and Martin\\rStreet;\\rAPN 005...   \n1  APNs 005-031-070 + 47 others;\\rSteve Courter W...   \n2                2665 Geneva Avenue\\rAPN 005-064-250   \n3      6098 Mission Street\\rAPNs 004-031-160 and 170   \n4               493 Eastmoor Avenue\\rAPN 008-082-200   \n\n              Proposed\\rUnit Type Site Size\\r(acres) Proposed\\rUnits Qty.  \\\n0                 Detached\\rhomes                1.9                   16   \n1                 Detached\\rhomes                8.3                  117   \n2                    Condominiums                1.0                    7   \n3             Apartment\\rbuilding               0.25                   36   \n4  Mixed-Use\\rApartment\\rbuilding               0.37                   71   \n\n   Proposed\\rDensity (du/ac)                     Status         Intake Date  \\\n0                        8.0         Under construction        June 8, 2015   \n1                       14.1         Under construction    October 29, 2015   \n2                        7.0  All entitlements\\rappoved      April 14, 2016   \n3                      144.0  All entitlements\\rappoved  September 13, 2016   \n4                      192.9              In plan check       June 18, 2019   \n\n   ... Site Size (acres) Unnamed: 1 Proposed Units Qty. Unnamed: 2  \\\n0  ...               NaN        NaN                 NaN        NaN   \n1  ...               NaN        NaN                 NaN        NaN   \n2  ...               NaN        NaN                 NaN        NaN   \n3  ...               NaN        NaN                 NaN        NaN   \n4  ...               NaN        NaN                 NaN        NaN   \n\n  ProposedDensity (du/ac)  Unnamed: 3  PlanningContact  Proposed\\rNew Sq. Ft.  \\\n0                     NaN         NaN              NaN                    NaN   \n1                     NaN         NaN              NaN                    NaN   \n2                     NaN         NaN              NaN                    NaN   \n3                     NaN         NaN              NaN                    NaN   \n4                     NaN         NaN              NaN                    NaN   \n\n   ProposedType  Planner  \n0           NaN      NaN  \n1           NaN      NaN  \n2           NaN      NaN  \n3           NaN      NaN  \n4           NaN      NaN  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Project Name</th>\n      <th>Application Type</th>\n      <th>Plan Case No.</th>\n      <th>Location/APN</th>\n      <th>Proposed\\rUnit Type</th>\n      <th>Site Size\\r(acres)</th>\n      <th>Proposed\\rUnits Qty.</th>\n      <th>Proposed\\rDensity (du/ac)</th>\n      <th>Status</th>\n      <th>Intake Date</th>\n      <th>...</th>\n      <th>Site Size (acres)</th>\n      <th>Unnamed: 1</th>\n      <th>Proposed Units Qty.</th>\n      <th>Unnamed: 2</th>\n      <th>ProposedDensity (du/ac)</th>\n      <th>Unnamed: 3</th>\n      <th>PlanningContact</th>\n      <th>Proposed\\rNew Sq. Ft.</th>\n      <th>ProposedType</th>\n      <th>Planner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Point Martin\\r- Phase One</td>\n      <td>Major subdivision</td>\n      <td>SUB-6-15-11016</td>\n      <td>Steve Courter Way and Martin\\rStreet;\\rAPN 005...</td>\n      <td>Detached\\rhomes</td>\n      <td>1.9</td>\n      <td>16</td>\n      <td>8.0</td>\n      <td>Under construction</td>\n      <td>June 8, 2015</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Point Martin\\r- Phase Two</td>\n      <td>General Plan\\rAmendment and\\rPD Zone Change</td>\n      <td>GPA-01-16-011884\\rPD-10-15-11781\\rCEQA-10-15-1...</td>\n      <td>APNs 005-031-070 + 47 others;\\rSteve Courter W...</td>\n      <td>Detached\\rhomes</td>\n      <td>8.3</td>\n      <td>117</td>\n      <td>14.1</td>\n      <td>Under construction</td>\n      <td>October 29, 2015</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pacific Place Retail\\rConversion</td>\n      <td>Zone Change\\rMajor Subdivision\\rDesign Review\\...</td>\n      <td>ZC-4-16-12036\\rSUB-4-16-12037\\rUP-4-16-12038\\r...</td>\n      <td>2665 Geneva Avenue\\rAPN 005-064-250</td>\n      <td>Condominiums</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>7.0</td>\n      <td>All entitlements\\rappoved</td>\n      <td>April 14, 2016</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mission Street/\\rGoethe Street\\rMixed-Use Buil...</td>\n      <td>Use Permit and\\rDesign Review</td>\n      <td>SUB-12-20-14799\\rUPR-9-16-12301\\rDR-9-16-012302</td>\n      <td>6098 Mission Street\\rAPNs 004-031-160 and 170</td>\n      <td>Apartment\\rbuilding</td>\n      <td>0.25</td>\n      <td>36</td>\n      <td>144.0</td>\n      <td>All entitlements\\rappoved</td>\n      <td>September 13, 2016</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Eastmoor\\rMixed-Use\\r(CORE)</td>\n      <td>Use Permit and\\rDesign Review</td>\n      <td>UPR-6-19-14076 and\\rDR-6-19-14077</td>\n      <td>493 Eastmoor Avenue\\rAPN 008-082-200</td>\n      <td>Mixed-Use\\rApartment\\rbuilding</td>\n      <td>0.37</td>\n      <td>71</td>\n      <td>192.9</td>\n      <td>In plan check</td>\n      <td>June 18, 2019</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Automation and Continuous Updating","metadata":{}},{"cell_type":"markdown","source":"To automate the data scraping and standardization processes, a robust system can be proposed that continuously updates the data sources. This involves setting up a scheduling mechanism, such as cron jobs, to ensure the data is refreshed at regular intervals, and implementing data standardization procedures to maintain consistency and quality.\n\n**Continuous Data Updates**\nTo ensure that the data sources are continuously updated, we can use a scheduling tool like cron jobs, which is a time-based job scheduler in Unix-like operating systems. Cron jobs allow us to automate the execution of scripts at specified times and intervals. This automation ensures that our scraping scripts run periodically, fetching the latest data from the target websites without manual intervention.\n\n**Scheduling with Cron Jobs**\nUsing cron jobs, we can schedule our web scraping scripts to run at intervals that suit the update frequency of our data sources. For example, if the data on the websites is updated daily, we can set the cron job to execute the scraping script once every day.","metadata":{}},{"cell_type":"code","source":"#Here is an example of how to set up a cron job for a Python scraping script:\n\n#1. Create the Scraping Script: Assume we have a script named scrape_data.py \n#    that performs the web scraping and data standardization tasks.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scrape_data.py\n\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_and_standardize():\n    url = 'https://example.com/projects'\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    # Extract and standardize data\n    projects = []\n    for project in soup.find_all('div', class_='project'):\n        title = project.find('h2').text.strip()\n        description = project.find('p').text.strip()\n        projects.append({'title': title, 'description': description})\n\n    # Save standardized data to a file or database\n    with open('projects.json', 'w') as f:\n        json.dump(projects, f, indent=4)\n\nif __name__ == \"__main__\":\n    scrape_and_standardize()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Set Up the Cron Job: Open the crontab configuration by running crontab -e in the \n# terminal and add the following line to schedule the script to run daily at midnight:","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0 0 * * * /usr/bin/python3 /path/to/scrape_data.py","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This cron job entry means the scrape_data.py script will be executed every day at 00:00 (midnight).\n\nProduction Environment Considerations\nIn a production environment, several additional considerations ensure the reliability and scalability of the automation system:\n\n* Error Handling and Logging: Implement robust error handling and logging within the scraping script to monitor the success and failure of each run. This helps in diagnosing issues and maintaining system health.\n\n* Notifications: Set up notifications (e.g., email alerts) to inform the system administrators of any critical errors or important events.\n\n* Version Control: Use version control systems (e.g., Git) to manage the codebase, enabling collaborative development and change tracking.\n\n* Scalability: Deploy the scraping scripts on scalable infrastructure (e.g., cloud services) to handle varying loads and ensure high availability.\n\n* Data Storage: Store the scraped data in a centralized, reliable database (e.g., PostgreSQL, MongoDB) that supports querying and analysis. Implement regular backups to prevent data loss.\n\nBy automating the data scraping and standardization processes with cron jobs and adhering to production standards, we can ensure the continuous and reliable updating of data sources, maintaining high data quality and consistency.","metadata":{}},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"markdown","source":"* In my web scraping project focused on construction and infrastructure projects and tenders in California, I encountered several challenges and implemented corresponding solutions to address them.\n\n* Understanding the different HTML structures of each website was a significant challenge. Each site had a unique layout, which made it difficult to extract data consistently. To overcome this, I invested time in thoroughly analyzing the HTML of each site and developed custom parsers to handle the variations.\n\n* Maintaining data quality and consistency was another major issue. Ensuring that the scraped data was accurate and consistent across different sources required significant effort. I implemented data validation checks and used data cleaning techniques to standardize and verify the quality of the extracted information.\n\n* Access restrictions on some websites posed additional difficulties. Certain sites did not permit automated scraping, making it hard to obtain the necessary data. To address this, I explored alternative methods such as using headless browsers and rotating IP addresses to mimic human behavior and access the data ethically within legal boundaries.\n\n* Furthermore, some websites provided data in poor quality, which complicated the extraction of the required information. To deal with this, I employed advanced text processing and natural language processing (NLP) techniques to clean and extract relevant data from poorly formatted sources.\n\n* By addressing these challenges with targeted solutions, I was able to effectively scrape and compile valuable data on construction and infrastructure projects and tenders in California.","metadata":{}}]}